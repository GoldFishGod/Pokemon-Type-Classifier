# -*- coding: utf-8 -*-
"""Copy of (Shuffled) RandomForestNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JVaSrC-2Aerg_KV93ZW4CZbG8hvPfTFW

## 1. Processing and saving dataset into Google Colab
"""

#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import shutil
import torch
import torchvision
import torchvision.datasets
from torchvision.datasets import ImageFolder
import torchvision.transforms as transforms
from PIL import Image
import tensorflow as tf

# Modelling
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from scipy.stats import randint

# Tree Visualisation
from sklearn.tree import export_graphviz
from IPython.display import Image
import graphviz

#mount drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount = True)

#main_path = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/NEURAL NETWORKS/random forest'
main_path = '/content/gdrive/MyDrive/APS360/NEURAL NETWORKS/random forest'
os.chdir(main_path)

#Assigning folders for data
#data_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/Type1_smaller_balanced_dataset'
data_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type1_smaller_balanced_dataset'

#train_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/Type1_smaller_balanced_dataset/Train'
#test_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/Type1_smaller_balanced_dataset/Test'
#small_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/type1_datasets/small'
train_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type1_smaller_balanced_dataset/Train'
val_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type1_smaller_balanced_dataset/Val'
test_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type1_smaller_balanced_dataset/Test'
small_folder = '/content/gdrive/MyDrive/APS360/DATASETS/type1_datasets/small'

#train2_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/Type2_smaller_balanced_dataset/Train'
#test2_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/Type2_smaller_balanced_dataset/Test'
#small2_folder = '/content/gdrive/MyDrive/Third Year/Summer 2023/APS360/DATASETS/type2_datasets/small'
train2_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type2_smaller_balanced_dataset/Train'
val2_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type2_smaller_balanced_dataset/Val'
test2_folder = '/content/gdrive/MyDrive/APS360/DATASETS/Type2_smaller_balanced_dataset/Test'
small2_folder = '/content/gdrive/MyDrive/APS360/DATASETS/type2_datasets/small'

#os.makedirs(train2_folder, exist_ok= True)
#os.makedirs(test2_folder, exist_ok= True)
#os.makedirs(small2_folder, exist_ok= True)

#checking to make sure correct zip files are in the right folder
os.chdir(data_folder)
!ls
os.chdir(main_path)
!ls

"""Need to delete all folders from previous runs from RandomForest folder, only data folder containing zip files and the ipynb colab file should exist."""

#unzipping data
!unzip data/train1.zip
!unzip data/test1.zip
!unzip data/small.zip
!unzip data/train2.zip
!unzip data/test2.zip
!unzip data/small2.zip

!ls

#defining function to preprocess images
transform = transforms.Compose([
    transforms.Resize((120, 120)),  # Resize the images to a fixed size
    transforms.ToTensor(),  # Convert the images to tensors
])

# Preprocess the images using ImageFolder
def preprocess_images(folder_path):
    dataset = ImageFolder(folder_path, transform=transform)

    return dataset

# create datasets
small_data = preprocess_images(small_folder)
train_data = preprocess_images(train_folder)
val_data  = preprocess_images(val_folder)
test_data = preprocess_images(test_folder)

small_data2 = preprocess_images(small2_folder)
train_data2 = preprocess_images(train2_folder)
val_data2  = preprocess_images(val2_folder)
test_data2 = preprocess_images(test2_folder)

#check number of samples in dataset
print("Number of training samples:",len(train_data))
print("Number of testing samples:",len(test_data))
print("Number of small samples", len(small_data))

print("Number of secondary type training samples:",len(train_data2))
print("Number of secondary type testing samples:",len(test_data2))
print("Number of secondary type small samples:",len(small_data2))

print(small_data)

#check to ensure expected label and image output
for img, label in small_data:
  print(label)
  #place the colour channel at the end, instead of at the beginning
  img = np.transpose(img, [1,2,0])
  plt.imshow(img)

#NEW SEPARATE FUNCTION: this separates but also shuffles the data
def shuffle_and_separate(dataset):
  list_samples = []
  for item in dataset: #convert imagefolder data into a list
    list_samples.append(item)

  random.shuffle(list_samples) #shuffle

  list_imgs = []
  list_labels = []

  for img, label in list_samples:
    list_imgs.append(img)
    list_labels.append(label)

  imgs = tuple(list_imgs)
  imgs = np.stack(imgs)
  labels = tuple(list_labels)
  labels = np.stack(labels)

  return imgs, labels

#separate all data into images and labels
small_img, small_label = shuffle_and_separate(small_data)
print(small_img.shape)
print(small_label.shape)

train_img, train_label = shuffle_and_separate(train_data)
print(train_img.shape)
print(train_label.shape)

val_img, val_label = shuffle_and_separate(val_data)
print(val_img.shape)
print(val_label.shape)

test_img, test_label = shuffle_and_separate(test_data)
print(test_img.shape)
print(test_label.shape)

small_img2, small_label2 = shuffle_and_separate(small_data2)
print(small_img2.shape)
print(small_label2.shape)

train_img2, train_label2 = shuffle_and_separate(train_data2)
print(train_img2.shape)
print(train_label2.shape)

val_img2, val_label2 = shuffle_and_separate(val_data2)
print(val_img2.shape)
print(val_label2.shape)

test_img2, test_label2 = shuffle_and_separate(test_data2)
print(test_img2.shape)
print(test_label2.shape)

#need to change sets into 2d array [num of images][dim*dim*num of channels]

nsamples, nx, ny, nrgb = train_img.shape
print(nsamples)
sk_train_img = train_img.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = val_img.shape
print(nsamples)
sk_val_img = val_img.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = test_img.shape
print(nsamples)
sk_test_img = test_img.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = small_img.shape
print(nsamples)
sk_small_img = small_img.reshape((nsamples,nx*ny*nrgb))
print(sk_small_img.shape)

nsamples, nx, ny, nrgb = train_img2.shape
print(nsamples)
sk_train_img2 = train_img2.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = val_img2.shape
print(nsamples)
sk_val_img2 = val_img2.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = test_img2.shape
print(nsamples)
sk_test_img2 = test_img2.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = small_img2.shape
print(nsamples)
sk_small_img2 = small_img2.reshape((nsamples,nx*ny*nrgb))
print(sk_small_img2.shape)

"""## 2. Setting up Random Forest Network

First, we check if the model can overfit. We use the small dataset, and as we can see, it does indeed overfit (100% accuracy).

"""

#initialize random forest model
shuffled_model = RandomForestClassifier()

#train the model
shuffled_model.fit(sk_small_img, small_label)

#prediction
y_pred = shuffled_model.predict(sk_small_img)

#accuracy check
accuracy = accuracy_score(small_label, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

#initialize random forest model
shuffled_model2 = RandomForestClassifier()

#train the model
shuffled_model2.fit(sk_train_img, train_label)

#prediction
y_pred_v = shuffled_model2.predict(sk_val_img)

#accuracy check
accuracy = accuracy_score(val_label, y_pred_v)
print("VAL ACCURACY OF THE MODEL: ", accuracy)

#prediction
y_pred = shuffled_model2.predict(sk_test_img)

#accuracy check
accuracy = accuracy_score(test_label, y_pred)
print("TEST ACCURACY OF THE MODEL: ", accuracy)

print(classification_report(val_label,y_pred_v))

print(classification_report(test_label,y_pred))

"""As we can see, the model had an accuracy of 49.22% when running on the shuffled data for the primary type! Pretty impressive considering random guessing would yield around 5%. Interesting to note how type 7 (ghost) and 14 (rock) had the highest f1 scores, while type 5 (fire) had the lowest. We can also look at the precisions, where fire actually has 100% precision. Looking at the classification report tells us that the Random Forest Classifier is better at detecting certain types more than others!"""

#########CAN IT OVERFIT

#initialize new random forest model
shuffled2_model = RandomForestClassifier()

#train the model
shuffled2_model.fit(sk_small_img2, small_label2)

#prediction
y_pred = shuffled2_model.predict(sk_small_img2)

#accuracy check
accuracy = accuracy_score(small_label2, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

#initialize random forest model
shuffled2_model2 = RandomForestClassifier()

#train the model
shuffled2_model2.fit(sk_train_img2, train_label2)

#prediction
y_pred_v = shuffled_model2.predict(sk_val_img2)

#accuracy check
accuracy = accuracy_score(val_label2, y_pred_v)
print("VAL ACCURACY OF THE MODEL: ", accuracy)

#prediction
y_pred = shuffled2_model2.predict(sk_test_img2)

#accuracy check
accuracy = accuracy_score(test_label2, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

print(classification_report(val_label2,y_pred_v))

print(classification_report(test_label2,y_pred))

"""Guessing the secondary type yielded an even higher accuracy, of 64.68%!

# BELOW THIS SECTION WILL BE CODE AND RESULTS CREATED AND USED WITHOUT SHUFFLING THE DATA or FAILED ATTEMPTS AT SHUFFLING
"""

#####FAILED
#defining function to preprocess images
transform = transforms.Compose([
    transforms.Resize((120, 120)),  # Resize the images to a fixed size
    transforms.ToTensor(),  # Convert the images to tensors
])

# Preprocess the images using ImageFolder
def preprocess_images2(folder_path):
    dataset = ImageFolder(folder_path, transform=transform)

    dataset = torch.utils.data.DataLoader(dataset,
                                               batch_size=len(dataset),
                                               shuffle=True)

    #some code that i deleted and forgot

    return dataset

#########USING NEW PREPROCESS
# create datasets
small_img, small_label = preprocess_images2(small_folder)
print(f"Number of small samples: {len(small_img)} {len(small_label)}")
train_img, train_label = preprocess_images2(train_folder)
test_img, test_label = preprocess_images2(test_folder)

small_img2, small_label2 = preprocess_images2(small2_folder)
train_img2, train_label2 = preprocess_images2(train2_folder)
test_img2, test_label2 = preprocess_images2(test2_folder)

#check number of samples in dataset
print(f"Number of training samples: {len(train_img)} {len(train_label)}")
print(f"Number of testing samples: {len(test_img)} {len(test_label)}")
print(f"Number of small samples: {len(small_img)} {len(small_label)}")

print(f"Number of secondary type training samples: {len(train_img2)} {len(train_label2)}")
print(f"Number of secondary type testing samples: {len(test_img2)} {len(test_label2)}")
print(f"Number of secondary type small samples: {len(small_img2)} {len(small_label2)}")

##### FAILED
imgs = []
labels = []
for img, label in small_data:
  img = np.array(img)
  label = np.array(label)
  imgs.append(img)
  labels.append(label)

imgs = tuple(imgs)
labels = tuple(labels)
imgs = np.stack(imgs)
labels = np.stack(labels)

print(imgs.shape)
print(labels.shape)

np_data = (imgs, labels)
np_data = np.hstack(np_data)
print(np_data.shape)

#Further preprocessing for sklearn random forest
#Need to separate images and labels for fit function

def separate(dataset):
  x = 0
  X = []
  y = []

  for img, label in dataset:
    img = img.numpy()
    X.append(img)
    y.append(label)

  X = tuple(X)
  X = np.stack(X)
  y = tuple(y)
  y = np.stack(y)

  return X, y

#separate all data into images and labels
small_img, small_label = separate(small_data)
print(small_img.shape)
print(small_label.shape)

train_img, train_label = separate(train_data)
print(train_img.shape)
print(train_label.shape)

test_img, test_label = separate(test_data)
print(test_img.shape)
print(test_label.shape)

small_img2, small_label2 = separate(small_data2)
print(small_img2.shape)
print(small_label2.shape)

train_img2, train_label2 = separate(train_data2)
print(train_img2.shape)
print(train_label2.shape)

test_img2, test_label2 = separate(test_data2)
print(test_img2.shape)
print(test_label2.shape)

#need to change sets into 2d array [num of images][dim*dim*num of channels]

nsamples, nx, ny, nrgb = train_img.shape
print(nsamples)
sk_train_img = train_img.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = test_img.shape
print(nsamples)
sk_test_img = test_img.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = small_img.shape
print(nsamples)
sk_small_img = small_img.reshape((nsamples,nx*ny*nrgb))
print(sk_small_img.shape)

nsamples, nx, ny, nrgb = train_img2.shape
print(nsamples)
sk_train_img2 = train_img2.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = test_img2.shape
print(nsamples)
sk_test_img2 = test_img2.reshape((nsamples,nx*ny*nrgb))

nsamples, nx, ny, nrgb = small_img2.shape
print(nsamples)
sk_small_img2 = small_img2.reshape((nsamples,nx*ny*nrgb))
print(sk_small_img2.shape)

"""## 2. Setting up Random Forest Network

First, we check if the model can overfit. We use the small dataset, and as we can see, it does indeed overfit (100% accuracy).

"""

#initialize random forest model
rfc_model = RandomForestClassifier()

#train the model
rfc_model.fit(sk_small_img, small_label)

#prediction
y_pred = rfc_model.predict(sk_small_img)

#accuracy check
accuracy = accuracy_score(small_label, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

"""Now, we can train the model with the saved train and test datasets."""

#train the model
rfc_model.fit(sk_train_img, train_label)

#prediction
y_pred = rfc_model.predict(sk_test_img)

#accuracy check
accuracy = accuracy_score(test_label, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

"""As we can see, the accuracy of our model was 48.68%! Pretty impressive, considering there were 18 different Pokemon types for it to distinguish between. Random guessing would yield around 5.56%. If we run it again, it will likely be slightly different, as the decisions trees are random."""

print(classification_report(test_label,y_pred))

"""Here we can see that some types were more accurately predicted than others! 7 (flying) and 14 (pyschic) were the two highest, with 80% and 62% f1 scores respectively. The lowest was 5 (fighting) with a 22% f1 score. This hints at us that certain Pokemon types are harder to distinguish than others, which makes sense; some are hard to distinguish for humans too! However, also note that pyschic types only had 3 samples; this may have affected the resultant accuracy.

Now, lets initialize another instance, and see the model's ability to distinguish secondary types. We need to download and process that data too!
"""

#########CAN IT OVERFIT

#initialize new random forest model
rfc_model2 = RandomForestClassifier()

#train the model
rfc_model2.fit(sk_small_img2, small_label2)

#prediction
y_pred = rfc_model2.predict(sk_small_img2)

#accuracy check
accuracy = accuracy_score(small_label2, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

#train the model
rfc_model2.fit(sk_train_img2, train_label2)

#prediction
y_pred = rfc_model2.predict(sk_test_img2)

#accuracy check
accuracy = accuracy_score(test_label2, y_pred)
print("ACCURACY OF THE MODEL: ", accuracy)

print(classification_report(test_label2,y_pred))

"""Wow! The decision tree model was even better at predicting the secondary types! It had an accuracy of 64.32%."""
